{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes On Amazon Fine Food Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ CONTENTS ] \n",
    "\n",
    "1. About the dataset<br>\n",
    "2. Objective<br>\n",
    "3. Loading the data<br>\n",
    "4. Data Preprocessing <br>\n",
    "5. Naive Bayes on k-Fold cross validation<br>\n",
    "6. Bag of Words (BoW)<br>\n",
    "    6.1 Bi-Grams & N-Grams<br>\n",
    "7. TF-IDF<br>\n",
    "8. Conclusion<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About the dataset\n",
    "1. Title: Amazon Fine Food Reviews. Link:https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "2. Relevant Information: This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n",
    "3. Data includes:\n",
    "    * Number of reviews: 568,454<br>\n",
    "    * Number of users: 256,059<br>\n",
    "    * Number of products: 74,258<br>\n",
    "    * Timespan: Oct 1999 - Oct 2012<br>\n",
    "    * Number of Attributes/Columns in data: 10 \n",
    "4. Attribute Information: \n",
    "    * Id\n",
    "    * ProductId - unique identifier for the product\n",
    "    * UserId - unqiue identifier for the user\n",
    "    * ProfileName\n",
    "    * HelpfulnessNumerator - number of users who found the review helpful\n",
    "    * HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "    * Score - rating between 1 and 5\n",
    "    * Time - timestamp for the review\n",
    "    * Summary - brief summary of the review\n",
    "    * Text - text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objective:\n",
    "For a given Amazon review, classify it as \"Possitive\"(Rating of 4 or 5) or \"Negative\"(Rating of 1 or 2).<br>\n",
    "<br>\n",
    "Here I'm using naive bayes algorithm to classify reviews as 'positive' or 'negative'. To convert a review text to numerical features I'm using bag of words(BoW) and TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib \n",
    "import sqlite3\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the previously cleaned data\n",
    "connect = sqlite3.connect('final_data.sqlite')\n",
    "\n",
    "#Ignoring the rows which have rating 3\n",
    "data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "\"\"\", connect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-processed data using sqlite. This dataset has no entry with score 3 which is previously removed. And the scores which are greater than 3 are denoted as 'positive' and which are less than 3 are denoted as 'negative' scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138688</td>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>b'grew read sendak book watch realli rosi movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138689</td>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "      <td>b'fun way children learn month year learn poem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138690</td>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "      <td>b'great littl book read nice rhythm well good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138691</td>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>b'book poetri month year goe month cute littl ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      Id   ProductId          UserId                  ProfileName  \\\n",
       "0  138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "1  138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "2  138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "3  138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "4  138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     0                       0  positive   939340800   \n",
       "1                     1                       1  positive  1194739200   \n",
       "2                     1                       1  positive  1191456000   \n",
       "3                     1                       1  positive  1076025600   \n",
       "4                     3                       4  positive  1018396800   \n",
       "\n",
       "                                      Summary  \\\n",
       "0                   EVERY book is educational   \n",
       "1  Love the book, miss the hard cover version   \n",
       "2               chicken soup with rice months   \n",
       "3      a good swingy rhythm for reading aloud   \n",
       "4             A great way to learn the months   \n",
       "\n",
       "                                                Text  \\\n",
       "0  this witty little book makes my son laugh at l...   \n",
       "1  I grew up reading these Sendak books, and watc...   \n",
       "2  This is a fun way for children to learn their ...   \n",
       "3  This is a great little book to read aloud- it ...   \n",
       "4  This is a book of poetry about the months of t...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'witti littl book make son laugh loud recit c...  \n",
       "1  b'grew read sendak book watch realli rosi movi...  \n",
       "2  b'fun way children learn month year learn poem...  \n",
       "3  b'great littl book read nice rhythm well good ...  \n",
       "4  b'book poetri month year goe month cute littl ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded data is imbalanced and here, I'm using downsampling method to balance this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the data based on time-stamp\n",
    "sorted_data = data.sort_values('Time', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 'positive' score to 1 and 'negative' score to 0\n",
    "def partition(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "actualScore = sorted_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "sorted_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>138683</td>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "      <td>b'rememb see show air televis year ago child s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>417839</td>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "      <td>b'beetlejuic well written movi everyth excel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>346055</td>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "      <td>b'twist rumplestiskin captur film star michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>417838</td>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "      <td>b'beetlejuic excel funni movi keaton hilari wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      Id   ProductId          UserId               ProfileName  \\\n",
       "0    138706  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
       "30   138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
       "424  417839  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
       "330  346055  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
       "423  417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "\n",
       "     HelpfulnessNumerator  HelpfulnessDenominator  Score       Time  \\\n",
       "0                       0                       0      1  939340800   \n",
       "30                      2                       2      1  940809600   \n",
       "424                     0                       0      1  944092800   \n",
       "330                     1                       2      1  944438400   \n",
       "423                     0                       0      1  946857600   \n",
       "\n",
       "                                               Summary  \\\n",
       "0                            EVERY book is educational   \n",
       "30   This whole series is great way to spend time w...   \n",
       "424                               Entertainingl Funny!   \n",
       "330                            A modern day fairy tale   \n",
       "423                                         FANTASTIC!   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    this witty little book makes my son laugh at l...   \n",
       "30   I can remember seeing the show when it aired o...   \n",
       "424  Beetlejuice is a well written movie ..... ever...   \n",
       "330  A twist of rumplestiskin captured on film, sta...   \n",
       "423  Beetlejuice is an excellent and funny movie. K...   \n",
       "\n",
       "                                           CleanedText  \n",
       "0    b'witti littl book make son laugh loud recit c...  \n",
       "30   b'rememb see show air televis year ago child s...  \n",
       "424  b'beetlejuic well written movi everyth excel a...  \n",
       "330  b'twist rumplestiskin captur film star michael...  \n",
       "423  b'beetlejuic excel funni movi keaton hilari wa...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.array(sorted_data.Score.reshape(sorted_data.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes & K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, score):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, score, test_size = 0.3, shuffle = False)\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying Multinomial Naive Bayes and cross-validating\n",
    "def cross_val(X, Y, vectorizer):\n",
    "\n",
    "    # spliting the train data set into cross validation train and cross validation test\n",
    "    kfold = KFold(3, shuffle=False, random_state=1)\n",
    "\n",
    "    alpha_val = [0.00001,0.00005,0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000]\n",
    "    cv_err = []\n",
    "    train_err = []\n",
    "\n",
    "    for train, cv in kfold.split(X):\n",
    "        for i in alpha_val:\n",
    "            nb = MultinomialNB(i, fit_prior=True, class_prior=None)\n",
    "\n",
    "            vect_model = vectorizer.fit(X.iloc[train]['CleanedText'].values)\n",
    "            train_vect = vect_model.transform(X.iloc[train]['CleanedText'].values)\n",
    "            cv_vect = vect_model.transform(X.iloc[cv]['CleanedText'].values)\n",
    "            \n",
    "            # fitting the model on cross-validation train\n",
    "            nb.fit(train_vect, Y[train])\n",
    "\n",
    "            # predict the response on the cross-validation train\n",
    "            train_err.append(1 - (nb.score(train_vect, Y[train])))\n",
    "            cv_err.append(1 - (nb.score(cv_vect, Y[cv])))\n",
    "\n",
    "    return train_err, cv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing model errors on cv and train data\n",
    "def error_comparision(train_err, cv_err):\n",
    "    sns.set()\n",
    "    alpha_val = [0.00001,0.00005,0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000]\n",
    "    # plotting error curves\n",
    "    for i in range(3):\n",
    "        plt.figure(1)\n",
    "        plt.figure(figsize=(9,12))\n",
    "        plt.subplot(3,1,i+1)\n",
    "        plt.plot(alpha_val, cv_err[i, :],label = 'cv_error', color = 'r')\n",
    "        plt.plot(alpha_val, train_err[i, :],label = 'train_error', color = 'b')\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Alpha-Values')\n",
    "        plt.ylabel('Error Values')\n",
    "        plt.legend()\n",
    "        plt.title('CV & TRAIN-ERR for Fold '+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting ROC curve along with confusion matrix\n",
    "def final_test_acc(train_data, train_score, test_data, test_score, best_a, name):\n",
    "    nb = MultinomialNB(best_a, fit_prior=True, class_prior=None)\n",
    "    nb.fit(train_data, train_score)\n",
    "    \n",
    "    \n",
    "    # TRAIN METRIC\n",
    "    \n",
    "    print('\\t\\t\\tACCURACY METRIC FOR TRAIN-SET\\n')\n",
    "    pred_trn = nb.predict(train_data)\n",
    "    acc_trn = accuracy_score(train_score, pred, normalize=True) * float(100)\n",
    "    print(\"\\nTrain accuracy for alpha = '{0}' is '{1}'\".format(best_a, acc_trn))\n",
    "    ytrn_pred_proba = nb.predict_proba(train_data)[::,1]\n",
    "    fpr0, tpr0, thresholds0 = roc_curve(train_score, ytrn_pred_proba)\n",
    "    \n",
    "    sns.set()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.plot(fpr0, tpr0, label='NB', color = 'r')\n",
    "    plt.xlabel('False-Positive Rate')\n",
    "    plt.ylabel('True-Positive Rate')\n",
    "    plt.title('NB ROC curve for '+name+' with alpha '+str(best_a))\n",
    "    plt.show()\n",
    "    print('Area under the ROC curve is ', roc_auc_score(train_score, ytrn_pred_proba))\n",
    "    conf_matx_trn = confusion_matrix(train_score, pred_trn)\n",
    "    print('\\nConfusion Matrix :\\n', conf_matx_trn)\n",
    "    norm_conf_matx_trn = conf_matx_trn / conf_matx_trn.astype(np.float).sum(axis=1).reshape(2,1)\n",
    "    print('\\nNormalized Confusion Matrix :\\n', norm_conf_matx_trn)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plot = sns.heatmap(conf_matx_trn, annot=True, fmt = 'g', cmap = 'RdPu',\\\n",
    "                       xticklabels=['Negative Review', 'Positive Review'], yticklabels=['Negative Review','Positive Review'])\n",
    "    plot.set_yticklabels(plot.get_yticklabels(), rotation = 0, fontsize = 10)\n",
    "    plt.title('Confusion Matrix Heatmap', fontsize=18)\n",
    "    \n",
    "    precision_trn, recall_trn, fscore_trn, support_trn = prf1(train_score, pred_trn)\n",
    "    print('\\nPrecision  : {0:.2f}%, {1:.2f}%'.format(precision_trn[0]*100, precision_trn[1]*100))\n",
    "    print('Recall     : {0:.2f}%, {1:.2f}%'.format(recall_trn[0]*100, recall_trn[1]*100))\n",
    "    print('F1-score   : {}'.format(fscore_trn))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TEST METRIC\n",
    "    \n",
    "    print('\\t\\t\\tACCURACY METRIC FOR TEST-SET\\n')\n",
    "    pred = nb.predict(test_data)\n",
    "    acc = accuracy_score(test_score, pred, normalize=True) * float(100)\n",
    "    \n",
    "    print(\"\\nTest accuracy for alpha = '{0}' is '{1}'\".format(best_a, acc))\n",
    "    y_pred_proba = nb.predict_proba(test_data)[::,1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_score, y_pred_proba)\n",
    "    \n",
    "    sns.set()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.plot(fpr, tpr, label='NB', color = 'r')\n",
    "    plt.xlabel('False-Positive Rate')\n",
    "    plt.ylabel('True-Positive Rate')\n",
    "    plt.title('NB ROC curve for '+name+' with alpha '+str(best_a))\n",
    "    plt.show()\n",
    "    print('Area under the ROC curve is ', roc_auc_score(test_score, y_pred_proba))\n",
    "    conf_matx = confusion_matrix(test_score,pred)\n",
    "    print('\\nConfusion Matrix :\\n', conf_matx)\n",
    "    norm_conf_matx = conf_matx / conf_matx.astype(np.float).sum(axis=1).reshape(2,1)\n",
    "    print('\\nNormalized Confusion Matrix :\\n', norm_conf_matx)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plot = sns.heatmap(conf_matx, annot=True, fmt = 'g', cmap = 'RdPu',\\\n",
    "                       xticklabels=['Negative Review', 'Positive Review'], yticklabels=['Negative Review','Positive Review'])\n",
    "    plot.set_yticklabels(plot.get_yticklabels(), rotation = 0, fontsize = 10)\n",
    "    plt.title('Confusion Matrix Heatmap', fontsize=18)\n",
    "    \n",
    "    precision, recall, fscore, support = prf1(test_score, pred)\n",
    "    print('\\nPrecision  : {0:.2f}%, {1:.2f}%'.format(precision[0]*100, precision[1]*100))\n",
    "    print('Recall     : {0:.2f}%, {1:.2f}%'.format(recall[0]*100, recall[1]*100))\n",
    "    print('F1-score   : {}'.format(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding top features for each class\n",
    "def top_features(X, vectorizer, top_n, alpha):\n",
    "    nb = MultinomialNB(alpha, fit_prior=True, class_prior=None)\n",
    "    nb.fit(X, train_y)\n",
    "    \n",
    "    pos_class_prob_sorted = nb.feature_log_prob_[0, :].argsort()\n",
    "    neg_class_prob_sorted = nb.feature_log_prob_[1, :].argsort()\n",
    "\n",
    "\n",
    "    print('Top '+str(top_n)+' \"NEGATIVE\" Features are:\\n')\n",
    "    print(np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[:top_n]))\n",
    "    print('\\nTop '+str(top_n)+' \"POSITIVE\" Features are:\\n')\n",
    "    print(np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[:top_n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid parameters passed: {'shuffle': False}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7e708df7919c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-c694d9b7495e>\u001b[0m in \u001b[0;36mdata_split\u001b[0;34m(data, score)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid parameters passed: {'shuffle': False}"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = data_split(sorted_data, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Bag of Word to cleaned text \n",
    "#In sklearn BoW is known as CountVectorizer\n",
    "count_vect = CountVectorizer(min_df=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculating cv-error and test error\n",
    "train_err_bow, cv_err_bow = cross_val(train_x, train_y, count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_err_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_err_bow = np.reshape(cv_err_bow,(3, 19))\n",
    "train_err_bow = np.reshape(train_err_bow,(3, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cv and test error for 3-Fold cross validation\n",
    "error_comparision(train_err_bow, cv_err_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* From cv-train and cv-test error comparision it seems like alpha should be 10 as elbow shape is at 10 alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model = count_vect.fit(train_x['CleanedText'].values)\n",
    "final_counts_train = bow_model.transform(train_x['CleanedText'].values)\n",
    "final_counts_test = bow_model.transform(test_x['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(count_vect.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance on test data\n",
    "final_test_acc(final_counts_train, train_y, final_counts_test, test_y, 1, 'BoW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* Test accuracy for alpha=10 is 86% if we use BoW representaion for our text-data, which is pretty good.\n",
    "* True positive and true negative rates are also high, which is 85% & 87%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing top 10 words(features) for each class\n",
    "top_features(final_counts_train, count_vect, 10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Bag of Words(Bi-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying BoW(Bi-Gram)\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating cv error and test error\n",
    "train_err_bigram, cv_err_bigram = cross_val(train_x, train_y, count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_err_bigram = np.reshape(cv_err_bigram,(3, 19))\n",
    "train_err_bigram = np.reshape(train_err_bigram,(3, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cv and test error for 3-Fold cross validation\n",
    "error_comparision(train_err_bigram, cv_err_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* For BoW(Bi-Gram), we are getting the alpha=1 from 3-Fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = count_vect.fit(train_x['CleanedText'].values)\n",
    "final_counts_train = bow_model.transform(train_x['CleanedText'].values)\n",
    "final_counts_test = bow_model.transform(test_x['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance on test data\n",
    "final_test_acc(final_counts_train, train_y, final_counts_test, test_y, 0.1, 'BoW(Bi-Gram)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* The test accuracy for BoW(Bi-Gram) is little better than that of BoW(Uni-Gram). As the accuracy is 89.17%.\n",
    "* True positive and true negative rates are also very high(i.e 89% for both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing top 10 words(features) for each class\n",
    "top_features(final_counts_train, count_vect, 10, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying tf-idf vectorization \n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating cv and test error\n",
    "train_err_tfidf, cv_err_tfidf = cross_val(train_x, train_y, tf_idf_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_err_tfidf = np.reshape(cv_err_tfidf,(3, 19))\n",
    "train_err_tfidf = np.reshape(train_err_tfidf,(3, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting cv and test error for 3-Fold cross validation\n",
    "error_comparision(train_err_tfidf, cv_err_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* We are getting a minimum error at alpha=0.8. So best-fit alpha should be 0.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = tf_idf_vect.fit(train_x['CleanedText'].values)\n",
    "final_tfidf_train = tfidf_model.transform(train_x['CleanedText'].values)\n",
    "final_tfidf_test = tfidf_model.transform(test_x['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performance on test data\n",
    "final_test_acc(final_tfidf_train, train_y, final_tfidf_test, test_y, 0.01, 'TF-IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* For TF-IDF we are getting nearly similar result to the BoW(Bi-Gram), but a little better.\n",
    "* The overall accuracy of this model for TF-IDF is 89.6%.\n",
    "* True positive and true negative rates are also high, which is 89% and 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing top 10 words(features) for each class\n",
    "top_features(final_tfidf_train, tf_idf_vect, 10, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Naive Bayes algorithm's performance for text classification is outstanding, as Naive Bayes is considered as a base-model for text-classification task.\n",
    "* For our data-set Naive Bayes performs best(i.e ~ 89.6%) for TF-IDF representation of text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
