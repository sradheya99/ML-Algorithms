{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algorithms on Amazon Fine Food Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ CONTENTS ] \n",
    "\n",
    "1. About the dataset<br>\n",
    "2. Objective<br>\n",
    "3. Loading the data<br>\n",
    "4. Data Preprocessing <br>\n",
    "5. Function Definitions<br>\n",
    "6. Bag of Words (BoW)<br>\n",
    "7. TF-IDF<br>\n",
    "8. Word2Vec<br>\n",
    "9. Avg W2V & TFIDF-W2V<br>\n",
    "    9.1 TF-IDF weighted W2V\n",
    "10. Summary<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About the dataset\n",
    "1. Title: Amazon Fine Food Reviews. Link:https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "2. Relevant Information: This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n",
    "3. Data includes:\n",
    "    * Number of reviews: 568,454<br>\n",
    "    * Number of users: 256,059<br>\n",
    "    * Number of products: 74,258<br>\n",
    "    * Timespan: Oct 1999 - Oct 2012<br>\n",
    "    * Number of Attributes/Columns in data: 10 \n",
    "4. Attribute Information: \n",
    "    * Id\n",
    "    * ProductId - unique identifier for the product\n",
    "    * UserId - unqiue identifier for the user\n",
    "    * ProfileName\n",
    "    * HelpfulnessNumerator - number of users who found the review helpful\n",
    "    * HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "    * Score - rating between 1 and 5\n",
    "    * Time - timestamp for the review\n",
    "    * Summary - brief summary of the review\n",
    "    * Text - text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objective:\n",
    "For given Amazon reviews, cluster them into groups using unsupervised algorithms.<br>\n",
    "<br>\n",
    "Here I'm using various clustering algorithms(K-means, K-medoid, Hirarchical, DBSCAN) to cluster the reviews into different groups. To convert a review text to numerical features I'm using bag of words(BoW), TF-IDF, Word2Vec and TF-IDF weighted Word2Vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib \n",
    "import sqlite3\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the previously cleaned data\n",
    "connect = sqlite3.connect('final_data.sqlite')\n",
    "\n",
    "#Ignoring the rows which have rating 3\n",
    "data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "\"\"\", connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138688</td>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>b'grew read sendak book watch realli rosi movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138689</td>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "      <td>b'fun way children learn month year learn poem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138690</td>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "      <td>b'great littl book read nice rhythm well good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138691</td>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>b'book poetri month year goe month cute littl ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      Id   ProductId          UserId                  ProfileName  \\\n",
       "0  138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "1  138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "2  138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "3  138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "4  138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     0                       0  positive   939340800   \n",
       "1                     1                       1  positive  1194739200   \n",
       "2                     1                       1  positive  1191456000   \n",
       "3                     1                       1  positive  1076025600   \n",
       "4                     3                       4  positive  1018396800   \n",
       "\n",
       "                                      Summary  \\\n",
       "0                   EVERY book is educational   \n",
       "1  Love the book, miss the hard cover version   \n",
       "2               chicken soup with rice months   \n",
       "3      a good swingy rhythm for reading aloud   \n",
       "4             A great way to learn the months   \n",
       "\n",
       "                                                Text  \\\n",
       "0  this witty little book makes my son laugh at l...   \n",
       "1  I grew up reading these Sendak books, and watc...   \n",
       "2  This is a fun way for children to learn their ...   \n",
       "3  This is a great little book to read aloud- it ...   \n",
       "4  This is a book of poetry about the months of t...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'witti littl book make son laugh loud recit c...  \n",
       "1  b'grew read sendak book watch realli rosi movi...  \n",
       "2  b'fun way children learn month year learn poem...  \n",
       "3  b'great littl book read nice rhythm well good ...  \n",
       "4  b'book poetri month year goe month cute littl ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = data.sort_values('Time', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>138683</td>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "      <td>b'rememb see show air televis year ago child s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>417839</td>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "      <td>b'beetlejuic well written movi everyth excel a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>346055</td>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "      <td>b'twist rumplestiskin captur film star michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>417838</td>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "      <td>b'beetlejuic excel funni movi keaton hilari wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      Id   ProductId          UserId               ProfileName  \\\n",
       "0    138706  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
       "30   138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
       "424  417839  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
       "330  346055  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
       "423  417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "\n",
       "     HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "0                       0                       0  positive  939340800   \n",
       "30                      2                       2  positive  940809600   \n",
       "424                     0                       0  positive  944092800   \n",
       "330                     1                       2  positive  944438400   \n",
       "423                     0                       0  positive  946857600   \n",
       "\n",
       "                                               Summary  \\\n",
       "0                            EVERY book is educational   \n",
       "30   This whole series is great way to spend time w...   \n",
       "424                               Entertainingl Funny!   \n",
       "330                            A modern day fairy tale   \n",
       "423                                         FANTASTIC!   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    this witty little book makes my son laugh at l...   \n",
       "30   I can remember seeing the show when it aired o...   \n",
       "424  Beetlejuice is a well written movie ..... ever...   \n",
       "330  A twist of rumplestiskin captured on film, sta...   \n",
       "423  Beetlejuice is an excellent and funny movie. K...   \n",
       "\n",
       "                                           CleanedText  \n",
       "0    b'witti littl book make son laugh loud recit c...  \n",
       "30   b'rememb see show air televis year ago child s...  \n",
       "424  b'beetlejuic well written movi everyth excel a...  \n",
       "330  b'twist rumplestiskin captur film star michael...  \n",
       "423  b'beetlejuic excel funni movi keaton hilari wa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_cluster(data, vectorizer, name):\n",
    "    if name in ['BoW','TFIDF']:\n",
    "                \n",
    "                vect_model = vectorizer.fit(X.iloc[train]['CleanedText'].values)\n",
    "                train_vect = vect_model.transform(X.iloc[train]['CleanedText'].values)\n",
    "                cv_vect = vect_model.transform(X.iloc[cv]['CleanedText'].values)\n",
    "            \n",
    "                clf = DecisionTreeClassifier(max_depth=d, criterion='gini', class_weight='balanced') \n",
    "                clf.fit(train_vect, Y[train])\n",
    "                \n",
    "                train_err.append(1 - (clf.score(train_vect, Y[train])))\n",
    "                cv_err.append(1 - (clf.score(cv_vect, Y[cv])))\n",
    "            \n",
    "            elif name == 'Word2Vec':\n",
    "                \n",
    "                w2v_model = gensim.models.Word2Vec(X[train], min_count=5, size=100, workers=8)\n",
    "                train_vect = avg_w2v(X[train], w2v_model)\n",
    "                cv_vect = avg_w2v(X[cv], w2v_model)\n",
    "            \n",
    "                clf = DecisionTreeClassifier(max_depth=d, criterion='gini', class_weight='balanced') \n",
    "                clf.fit(train_vect, Y[train])\n",
    "                \n",
    "                cv_err.append(1 - (clf.score(cv_vect, Y[cv])))\n",
    "                train_err.append(1 - (clf.score(train_vect, Y[train])))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                raw_x = vectorizer # its the text data n't a vectorizer for tfidf-w2v \n",
    "                X1 = np.array(X)\n",
    "                w2v_model = gensim.models.Word2Vec(X1[train], min_count=5, size=100, workers=-1)\n",
    "                tfidf_dict = tf_idf_vect.fit_transform(raw_x[train])\n",
    "                train_vect = tfidf_w2v(X[cv.shape[0]:], w2v_model, tfidf_dict)\n",
    "                cv_vect = tfidf_w2v(X[:cv.shape[0]], w2v_model, tfidf_dict)\n",
    "                \n",
    "                train_vect = np.nan_to_num(train_vect)\n",
    "                cv_vect = np.nan_to_num(cv_vect)\n",
    "            \n",
    "                clf = DecisionTreeClassifier(max_depth=d, criterion='gini', class_weight='balanced') \n",
    "                clf.fit(standardizer(train_vect), Y[train])\n",
    "                \n",
    "                cv_err.append(1 - (clf.score(standardizer(cv_vect), Y[cv])))\n",
    "                train_err.append(1 - (clf.score(standardizer(train_vect), Y[train])))\n",
    "                          \n",
    "    return train_err, cv_err\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
