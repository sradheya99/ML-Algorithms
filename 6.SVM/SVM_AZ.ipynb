{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM On Amazon Fine Food Reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ CONTENTS ] \n",
    "\n",
    "1. About the dataset<br>\n",
    "2. Objective<br>\n",
    "3. Loading the data<br>\n",
    "4. Data Preprocessing <br>\n",
    "5. Function Definitions<br>\n",
    "6. Bag of Words (BoW)<br>\n",
    "    6.1 Bi-Grams & N-Grams<br>\n",
    "7. TF-IDF<br>\n",
    "8. Word2Vec<br>\n",
    "9. Avg W2V & TFIDF-W2V<br>\n",
    "    9.1 TF-IDF weighted W2V\n",
    "10. Conclusion<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About the dataset\n",
    "1. Title: Amazon Fine Food Reviews. Link:https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "2. Relevant Information: This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories.\n",
    "3. Data includes:\n",
    "    * Number of reviews: 568,454<br>\n",
    "    * Number of users: 256,059<br>\n",
    "    * Number of products: 74,258<br>\n",
    "    * Timespan: Oct 1999 - Oct 2012<br>\n",
    "    * Number of Attributes/Columns in data: 10 \n",
    "4. Attribute Information: \n",
    "    * Id\n",
    "    * ProductId - unique identifier for the product\n",
    "    * UserId - unqiue identifier for the user\n",
    "    * ProfileName\n",
    "    * HelpfulnessNumerator - number of users who found the review helpful\n",
    "    * HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "    * Score - rating between 1 and 5\n",
    "    * Time - timestamp for the review\n",
    "    * Summary - brief summary of the review\n",
    "    * Text - text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objective:\n",
    "For a given Amazon review, classify it as \"Possitive\"(Rating of 4 or 5) or \"Negative\"(Rating of 1 or 2).<br>\n",
    "<br>\n",
    "Here I'm using Support Vector Machine(SVM) algorithm to classify reviews as 'positive' or 'negative'. To convert a review text to numerical features I'm using bag of words, TF-IDF, avg Word2Vec, TF-IDF weighted Word2Vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sradheya/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/sradheya/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# loading required libraries \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib \n",
    "import sqlite3\n",
    "import string\n",
    "import scipy \n",
    "import nltk\n",
    "import time\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#Standardizing the data\n",
    "def standardizer(data):\n",
    "    stnd_scaler = StandardScaler(with_mean=False)\n",
    "    stnd_matx = stnd_scaler.fit_transform(data)\n",
    "    return stnd_matx\n",
    "\n",
    "#Applying dimensionality reduction \n",
    "def truncated_svd(data):\n",
    "    svd = TruncatedSVD(n_components = 1000, random_state = 0)\n",
    "    svd_val = svd.fit_transform(data)\n",
    "    print(np.sum(svd.explained_variance_ratio_))\n",
    "    return svd_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "connect = sqlite3.connect('final_data.sqlite')\n",
    "\n",
    "#Ignoring the rows which have rating 3\n",
    "data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "\"\"\", connect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-processed data using sqlite. This dataset has no entry with score 3 which is previously removed. And the scores which are greater than 3 are denoted as 'positive' and which are less than 3 are denoted as 'negative' scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138688</td>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>b'grew read sendak book watch realli rosi movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138689</td>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "      <td>b'fun way children learn month year learn poem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138690</td>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "      <td>b'great littl book read nice rhythm well good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138691</td>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "      <td>b'book poetri month year goe month cute littl ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      Id   ProductId          UserId                  ProfileName  \\\n",
       "0  138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "1  138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "2  138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "3  138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "4  138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     0                       0  positive   939340800   \n",
       "1                     1                       1  positive  1194739200   \n",
       "2                     1                       1  positive  1191456000   \n",
       "3                     1                       1  positive  1076025600   \n",
       "4                     3                       4  positive  1018396800   \n",
       "\n",
       "                                      Summary  \\\n",
       "0                   EVERY book is educational   \n",
       "1  Love the book, miss the hard cover version   \n",
       "2               chicken soup with rice months   \n",
       "3      a good swingy rhythm for reading aloud   \n",
       "4             A great way to learn the months   \n",
       "\n",
       "                                                Text  \\\n",
       "0  this witty little book makes my son laugh at l...   \n",
       "1  I grew up reading these Sendak books, and watc...   \n",
       "2  This is a fun way for children to learn their ...   \n",
       "3  This is a great little book to read aloud- it ...   \n",
       "4  This is a book of poetry about the months of t...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'witti littl book make son laugh loud recit c...  \n",
       "1  b'grew read sendak book watch realli rosi movi...  \n",
       "2  b'fun way children learn month year learn poem...  \n",
       "3  b'great littl book read nice rhythm well good ...  \n",
       "4  b'book poetri month year goe month cute littl ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loaded data is imbalanced and logistic regression is very sensitive to imbalanced data as well as to mismatch between the class distribution of train-set and test-set. So, it is a good idea to upsample or downsample the data to balance the two classes. Here, I'm downsampling my data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = data[data.Score=='positive']\n",
    "df_minority = data[data.Score=='negative']\n",
    " \n",
    "# downsampling majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples=57110,  \n",
    "                                 random_state=1)   \n",
    " \n",
    "# combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114220, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>417838</td>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "      <td>b'beetlejuic excel funni movi keaton hilari wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>346116</td>\n",
       "      <td>374422</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1048CYU0OV4O8</td>\n",
       "      <td>Judy L. Eans</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>947376000</td>\n",
       "      <td>GREAT</td>\n",
       "      <td>THIS IS ONE MOVIE THAT SHOULD BE IN YOUR MOVIE...</td>\n",
       "      <td>b'one movi movi collect fill comedi action wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>346041</td>\n",
       "      <td>374343</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1B2IZU1JLZA6</td>\n",
       "      <td>Wes</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>negative</td>\n",
       "      <td>948240000</td>\n",
       "      <td>WARNING: CLAMSHELL EDITION IS EDITED TV VERSION</td>\n",
       "      <td>I, myself always enjoyed this movie, it's very...</td>\n",
       "      <td>b'alway enjoy movi funni entertain didnt hesit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1146</td>\n",
       "      <td>1245</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A29Z5PI9BW2PU3</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>positive</td>\n",
       "      <td>961718400</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>This was a really good idea and the final prod...</td>\n",
       "      <td>b'realli good idea final product outstand use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>346102</td>\n",
       "      <td>374408</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1GB1Q193DNFGR</td>\n",
       "      <td>Bruce Lee Pullen</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>970531200</td>\n",
       "      <td>Fabulous Comedic Fanasy Directed by a Master</td>\n",
       "      <td>Beetlejuice is an awe-inspiring wonderfully am...</td>\n",
       "      <td>b'beetlejuic wonder amus comed romp explor inc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      Id   ProductId          UserId               ProfileName  \\\n",
       "423  417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "245  346116  374422  B00004CI84  A1048CYU0OV4O8              Judy L. Eans   \n",
       "308  346041  374343  B00004CI84   A1B2IZU1JLZA6                       Wes   \n",
       "241    1146    1245  B00002Z754  A29Z5PI9BW2PU3                    Robbie   \n",
       "296  346102  374408  B00004CI84  A1GB1Q193DNFGR          Bruce Lee Pullen   \n",
       "\n",
       "     HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "423                     0                       0  positive  946857600   \n",
       "245                     2                       2  positive  947376000   \n",
       "308                    19                      23  negative  948240000   \n",
       "241                     7                       7  positive  961718400   \n",
       "296                     5                       5  positive  970531200   \n",
       "\n",
       "                                             Summary  \\\n",
       "423                                       FANTASTIC!   \n",
       "245                                            GREAT   \n",
       "308  WARNING: CLAMSHELL EDITION IS EDITED TV VERSION   \n",
       "241                                    Great Product   \n",
       "296     Fabulous Comedic Fanasy Directed by a Master   \n",
       "\n",
       "                                                  Text  \\\n",
       "423  Beetlejuice is an excellent and funny movie. K...   \n",
       "245  THIS IS ONE MOVIE THAT SHOULD BE IN YOUR MOVIE...   \n",
       "308  I, myself always enjoyed this movie, it's very...   \n",
       "241  This was a really good idea and the final prod...   \n",
       "296  Beetlejuice is an awe-inspiring wonderfully am...   \n",
       "\n",
       "                                           CleanedText  \n",
       "423  b'beetlejuic excel funni movi keaton hilari wa...  \n",
       "245  b'one movi movi collect fill comedi action wha...  \n",
       "308  b'alway enjoy movi funni entertain didnt hesit...  \n",
       "241  b'realli good idea final product outstand use ...  \n",
       "296  b'beetlejuic wonder amus comed romp explor inc...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the data according to the time-stamp\n",
    "sorted_data = df_downsampled.sort_values('Time', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "sorted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#Preparing the filtered data\n",
    "actualScore = sorted_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "sorted_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>417838</td>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "      <td>b'beetlejuic excel funni movi keaton hilari wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>346116</td>\n",
       "      <td>374422</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1048CYU0OV4O8</td>\n",
       "      <td>Judy L. Eans</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>947376000</td>\n",
       "      <td>GREAT</td>\n",
       "      <td>THIS IS ONE MOVIE THAT SHOULD BE IN YOUR MOVIE...</td>\n",
       "      <td>b'one movi movi collect fill comedi action wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>346041</td>\n",
       "      <td>374343</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1B2IZU1JLZA6</td>\n",
       "      <td>Wes</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>948240000</td>\n",
       "      <td>WARNING: CLAMSHELL EDITION IS EDITED TV VERSION</td>\n",
       "      <td>I, myself always enjoyed this movie, it's very...</td>\n",
       "      <td>b'alway enjoy movi funni entertain didnt hesit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1146</td>\n",
       "      <td>1245</td>\n",
       "      <td>B00002Z754</td>\n",
       "      <td>A29Z5PI9BW2PU3</td>\n",
       "      <td>Robbie</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>961718400</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>This was a really good idea and the final prod...</td>\n",
       "      <td>b'realli good idea final product outstand use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>346102</td>\n",
       "      <td>374408</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1GB1Q193DNFGR</td>\n",
       "      <td>Bruce Lee Pullen</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>970531200</td>\n",
       "      <td>Fabulous Comedic Fanasy Directed by a Master</td>\n",
       "      <td>Beetlejuice is an awe-inspiring wonderfully am...</td>\n",
       "      <td>b'beetlejuic wonder amus comed romp explor inc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      Id   ProductId          UserId               ProfileName  \\\n",
       "423  417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "245  346116  374422  B00004CI84  A1048CYU0OV4O8              Judy L. Eans   \n",
       "308  346041  374343  B00004CI84   A1B2IZU1JLZA6                       Wes   \n",
       "241    1146    1245  B00002Z754  A29Z5PI9BW2PU3                    Robbie   \n",
       "296  346102  374408  B00004CI84  A1GB1Q193DNFGR          Bruce Lee Pullen   \n",
       "\n",
       "     HelpfulnessNumerator  HelpfulnessDenominator  Score       Time  \\\n",
       "423                     0                       0      1  946857600   \n",
       "245                     2                       2      1  947376000   \n",
       "308                    19                      23      0  948240000   \n",
       "241                     7                       7      1  961718400   \n",
       "296                     5                       5      1  970531200   \n",
       "\n",
       "                                             Summary  \\\n",
       "423                                       FANTASTIC!   \n",
       "245                                            GREAT   \n",
       "308  WARNING: CLAMSHELL EDITION IS EDITED TV VERSION   \n",
       "241                                    Great Product   \n",
       "296     Fabulous Comedic Fanasy Directed by a Master   \n",
       "\n",
       "                                                  Text  \\\n",
       "423  Beetlejuice is an excellent and funny movie. K...   \n",
       "245  THIS IS ONE MOVIE THAT SHOULD BE IN YOUR MOVIE...   \n",
       "308  I, myself always enjoyed this movie, it's very...   \n",
       "241  This was a really good idea and the final prod...   \n",
       "296  Beetlejuice is an awe-inspiring wonderfully am...   \n",
       "\n",
       "                                           CleanedText  \n",
       "423  b'beetlejuic excel funni movi keaton hilari wa...  \n",
       "245  b'one movi movi collect fill comedi action wha...  \n",
       "308  b'alway enjoy movi funni entertain didnt hesit...  \n",
       "241  b'realli good idea final product outstand use ...  \n",
       "296  b'beetlejuic wonder amus comed romp explor inc...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.array(sorted_data.Score.reshape(114220,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [A.] Data Spliting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data\n",
    "def data_split(data, score):\n",
    "    # train data 70% and test data 30%\n",
    "    train_x, test_x, train_y, test_y = cross_validation.train_test_split(data, score, test_size=0.3, random_state=0)    \n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [B.] Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying Support Vector Classifier \n",
    "def support_vect_classifier(data, score):\n",
    "    train_x, test_x, train_y, test_y = data_split(data, score)\n",
    "    cv_err = []\n",
    "    train_err = []\n",
    "    gamma = [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0,10000.0]\n",
    "    c_val = [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0,10000.0]\n",
    "    # applying 3-Fold cross validation\n",
    "    Kfold = KFold(3, shuffle=False, random_state=36)\n",
    "    for train_data, cv_data in Kfold.split(train_x):\n",
    "        for g in gamma:\n",
    "            for c in c_val:\n",
    "                svc_model = SVC(kernel = 'rbf', degree = 3, C = c, gamma = g, random_state = 36)\n",
    "                svc_model.fit(train_x[train_data], train_y[train_data])\n",
    "                train_err.append(1 - (svc_model.score(train_x[train_data], train_y[train_data])))\n",
    "                cv_err.append(1 - (svc_model.score(train_x[cv_data], train_y[cv_data])))\n",
    "    return train_err, cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [C.] Error Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing error between cv and train data\n",
    "def error_comparision(cv_err, train_err):\n",
    "    sns.set()\n",
    "    c_val = [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0,10000.0]\n",
    "    gamma = [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0,10000.0]\n",
    "    for i in range(3):\n",
    "        plt.figure(1)\n",
    "        plt.figure(figsize=(9,12))\n",
    "        plt.subplot(3,1,i+1)\n",
    "        plt.plot(c_val, cv_err[i,:],label = 'cv_error')\n",
    "        plt.plot(c_val, train_err[i,:],label = 'train_error')\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('C-Values')\n",
    "        plt.ylabel('Error Values')\n",
    "        plt.legend()\n",
    "        plt.title('CV & TRAIN-ERR for Fold '+str(i+1))\n",
    "    for i in range(3):\n",
    "        plt.figure(1)\n",
    "        plt.figure(figsize=(9,12))\n",
    "        plt.subplot(3,1,i+1)\n",
    "        plt.plot(gamma, cv_err[i,:],label = 'cv_error')\n",
    "        plt.plot(gamma, train_err[i,:],label = 'train_error')\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('C-Values')\n",
    "        plt.ylabel('Error Values')\n",
    "        plt.legend()\n",
    "        plt.title('CV & TRAIN-ERR for Fold '+str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [D.] Accuracy Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy and ROC plot\n",
    "def final_test_acc(data,score,l,best_c,best_gamma,name):\n",
    "    train_x, test_x, train_y, test_y = data_split(data, score)\n",
    "    scv_model = SVC(kernel = 'rbf', degree = 3, C = best_c, gamma = best_gamma, random_state = 36)\n",
    "    svc_model.fit(train_x,train_y)\n",
    "    pred = svc_model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, pred, normalize=True) * float(100)\n",
    "    print(\"\\nTest accuracy for C = '{0}' is '{1}'\".format(best_c, acc))\n",
    "    \n",
    "    y_pred_proba = lr_model.predict_proba(test_x)[::,1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, y_pred_proba)\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "    plt.xlabel('False-Positive Rate')\n",
    "    plt.ylabel('True-Positive Rate')\n",
    "    plt.title('Logistic-Regression ROC curve for '+name)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Area under the ROC curve is ', roc_auc_score(test_y, y_pred_proba))\n",
    "    conf_matx = confusion_matrix(test_y,pred)\n",
    "    print('\\nConfusion Matrix :\\n', conf_matx)\n",
    "    norm_conf_matx = conf_matx / conf_matx.astype(np.float).sum(axis=1).reshape(2,1)\n",
    "    print('\\nNormalized Confusion Matrix :\\n', norm_conf_matx)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    plot = sns.heatmap(norm_conf_matx, annot=True, xticklabels=['Negative Review', 'Positive Review'], yticklabels=['Negative Review','Positive Review'])\n",
    "    plot.set_yticklabels(plot.get_yticklabels(), rotation = 0, fontsize = 10)\n",
    "    plt.title('Confusion Matrix Heatmap', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [E.] Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying grid search to find best c \n",
    "def grid_search_cv(data, score):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = data_split(data, score)\n",
    "    parameter = [{'C': [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0,10000.0],\\\n",
    "                   'gamma': [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1.0,5.0,10.0,50.0,100.0,500.0,1000.0,5000.0,10000.0]}]\n",
    "            \n",
    "    model = GridSearchCV(SVC(), parameters, scoring = 'f1', cv=3, n_jobs = 6)\n",
    "    model.fit(train_x, train_y.reshape(train_x.shape[0],))\n",
    "\n",
    "    print(model.best_estimator_)\n",
    "    print(model.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F.] Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying random search to find best c \n",
    "def random_search_cv(data, score, l):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = data_split(data, score)\n",
    "    parameters={'C': scipy.stats.norm(10), 'gamma': scipy.stats.norm(10)}\n",
    "    model = RandomizedSearchCV(SVC(), parameters, scoring = 'f1', cv=3)\n",
    "    model.fit(train_x,train_y)\n",
    "                                                                                   \n",
    "    print(model.best_estimator_)\n",
    "    print(model.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Bag of Word to cleaned text \n",
    "#In sklearn BoW is known as CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "final_counts = count_vect.fit_transform(sorted_data['CleanedText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114220, 41258)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column standardization \n",
    "final_counts = standardizer(final_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1666574334332846\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "final_counts = truncated_svd(final_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [A.] Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying svc and 3-fold cross validation\n",
    "train_bow, cv_bow = support_vect_classifier(final_counts, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
